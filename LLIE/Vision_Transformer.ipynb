{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-18T13:52:24.729347200Z",
     "start_time": "2023-07-18T13:52:22.256768Z"
    }
   },
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# 导入环境\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import paddle\n",
    "from paddle.io import Dataset\n",
    "from paddle.nn import Conv2D, MaxPool2D, Linear, Dropout, BatchNorm, AdaptiveAvgPool2D, AvgPool2D\n",
    "import paddle.nn.functional as F\n",
    "import paddle.nn as nn\n",
    "\n",
    "##########################################################################################\n",
    "##########################################################################################\n",
    "# 图像分块、Embedding\n",
    "# 定义了一个名为 PatchEmbed 的自定义图像块嵌入层。它将输入图像分成小的块，\n",
    "# 并将每个块通过一个卷积层进行投影（Embedding），从而将图像转换为一个序列形式的张量。\n",
    "##########################################################################################\n",
    "# PatchEmbed 类继承自 paddle.nn.Layer，并实现了 forward 方法来定义前向传播操作。主要步骤如下：\n",
    "# __init__ 方法：该方法初始化 PatchEmbed 类，接收以下参数：\n",
    "# img_size：输入图像的大小，默认为 224，可以是一个整数或一个元组 [H, W]。\n",
    "# patch_size：图像块的大小，默认为 16，同样可以是一个整数或一个元组 [H, W]。\n",
    "# in_chans：输入图像的通道数，默认为 3（RGB图像）。\n",
    "# embed_dim：块嵌入向量的维度，默认为 768。\n",
    "##########################################################################################\n",
    "# forward 方法：在前向传播过程中，通过卷积操作将图像块嵌入到一个向量序列中。具体步骤如下：\n",
    "# 首先，输入图像的维度为 [B, C, H, W]，其中 B 是批次大小，C 是通道数，H 和 W 是图像的高度和宽度。\n",
    "# 然后，代码通过一个卷积层 self.proj 将图像块投影（Embedding）到一个新的向量空间。\n",
    "# 这个投影操作与图像块的大小和嵌入向量的维度有关。\n",
    "# 接下来，通过 flatten 方法将卷积输出展平为一个形状为 [B, C, H*W] 的张量，其中 H*W 表示图像中的总块数。\n",
    "# 最后，通过 transpose 方法将维度重新排列为 [B, H*W, C]，这样每个块就成为序列中的一个元素，\n",
    "# 其中 H*W 表示序列的长度，C 是块嵌入向量的维度。\n",
    "##########################################################################################\n",
    "##########################################################################################\n",
    "class PatchEmbed(nn.Layer):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        # 原始大小为int，转为tuple，即：img_size原始输入224，变换后为[224,224]\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        # 图像块的个数\n",
    "        num_patches = (img_size[1] // patch_size[1]) * (img_size[0] // patch_size[0])\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "\n",
    "        self.proj = nn.Conv2D(\n",
    "            in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        # in_chans：输入图像的通道数，默认为 3（RGB图像）。\n",
    "        # embed_dim：块嵌入向量的维度，默认为 768。\n",
    "        # kernel_size：卷积核大小，默认为 patch_size。\n",
    "        # stride：卷积步长，默认为 patch_size。\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape # 将x.shape的四个维度分别赋值给这四个变量，x是张量。\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
    "            \"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\" # 用于检查输入图像的大小是否与模型期望的大小相匹配。\n",
    "        # [B, C, H, W] -> [B, C, H*W] ->[B, H*W, C]\n",
    "        x = self.proj(x).flatten(2).transpose((0, 2, 1))\n",
    "        # self.proj在__init__中定义为一个2D卷积核。\n",
    "        # flatten(2)表示将第2维度的数据展平，即：[B, C, H*W]\n",
    "        # transpose((0, 2, 1))表示将第1维度和第2维度的数据交换，即：[B, H*W, C]，这样刚好是序列数据的表示方式。\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "##########################################################################################\n",
    "# Multi-head Attention\n",
    "# Attention类实现了一个多头注意力(Multi-head Attention)模块，通常在自注意力机制(Self-Attention)中使用,\n",
    "# 用于计算注意力权重，然后对输入序列进行加权求和。多头注意力允许模型同时关注不同的子空间的特征，从而提高模型的表达能力。\n",
    "##########################################################################################\n",
    "# Attention 类的初始化方法 __init__：\n",
    "# dim：输入向量的维度。\n",
    "# num_heads：多头注意力的头数，用于将输入特征拆分成多个子空间。\n",
    "# qkv_bias：是否在线性层（self.qkv）中使用偏置项。\n",
    "# qk_scale：q 和 k 的缩放因子，默认为 None。若不提供，则使用 head_dim 的倒数（head_dim = dim // num_heads）的平方根。\n",
    "# attn_drop：在计算注意力矩阵时的 dropout 比例。\n",
    "# proj_drop：在输出时的 dropout 比例。\n",
    "##########################################################################################\n",
    "# forward 方法：在前向传播中，执行以下操作：\n",
    "# 获取输入张量的形状，其中 N 代表批次大小，C 代表输入向量的维度。\n",
    "# 通过线性变换 self.qkv 将输入张量 x 转换为三个部分：Query (q)、Key (k) 和 Value (v)。\n",
    "# 将 q, k, v 分别重塑为 (batch_size * num_heads, N, head_dim) 的张量。\n",
    "# 通过Transposed Dot-Product Attention计算注意力矩阵。首先将q与k进行点积（dot product），再进行缩放（scaled），然后通过Softmax函数进行归一化，得到注意力权重。\n",
    "# 对注意力矩阵应用Dropout（self.attn_drop）进行正则化。\n",
    "# 将注意力权重与v进行点积，然后重新变换形状，最后执行线性变换和输出向量的Dropout，并返回结果。\n",
    "##########################################################################################\n",
    "##########################################################################################\n",
    "class Attention(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 dim,\n",
    "                 num_heads=8,\n",
    "                 qkv_bias=False,\n",
    "                 qk_scale=None,\n",
    "                 attn_drop=0.,\n",
    "                 proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim**-0.5\n",
    "        # 计算 q,k,v 的转移矩阵\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias_attr=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        # 最终的线性层\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C = x.shape[1:]\n",
    "        # 线性变换\n",
    "        qkv = self.qkv(x).reshape((-1, N, 3, self.num_heads, C //\n",
    "                                   self.num_heads)).transpose((2, 0, 3, 1, 4))\n",
    "        # 分割 query key value\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        # Scaled Dot-Product Attention\n",
    "        # Matmul + Scale\n",
    "        attn = (q.matmul(k.transpose((0, 1, 3, 2)))) * self.scale\n",
    "        # SoftMax\n",
    "        attn = nn.functional.softmax(attn, axis=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        # Matmul\n",
    "        x = (attn.matmul(v)).transpose((0, 2, 1, 3)).reshape((-1, N, C))\n",
    "        # 线性变换\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T13:52:26.680413700Z",
     "start_time": "2023-07-18T13:52:26.669391600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
