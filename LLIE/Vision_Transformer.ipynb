{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# 导入环境\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import paddle\n",
    "from paddle.io import Dataset\n",
    "from paddle.nn import Conv2D, MaxPool2D, Linear, Dropout, BatchNorm, AdaptiveAvgPool2D, AvgPool2D\n",
    "import paddle.nn.functional as F\n",
    "import paddle.nn as nn\n",
    "\n",
    "##########################################################################################\n",
    "##########################################################################################\n",
    "# 图像分块、Embedding\n",
    "# 定义了一个名为 PatchEmbed 的自定义图像块嵌入层。它将输入图像分成小的块，\n",
    "# 并将每个块通过一个卷积层进行投影（Embedding），从而将图像转换为一个序列形式的张量。\n",
    "##########################################################################################\n",
    "# PatchEmbed 类继承自 paddle.nn.Layer，并实现了 forward 方法来定义前向传播操作。主要步骤如下：\n",
    "# __init__ 方法：该方法初始化 PatchEmbed 类，接收以下参数：\n",
    "# img_size：输入图像的大小，默认为 224，可以是一个整数或一个元组 [H, W]。\n",
    "# patch_size：图像块的大小，默认为 16，同样可以是一个整数或一个元组 [H, W]。\n",
    "# in_chans：输入图像的通道数，默认为 3（RGB图像）。\n",
    "# embed_dim：块嵌入向量的维度，默认为 768。\n",
    "##########################################################################################\n",
    "# forward 方法：在前向传播过程中，通过卷积操作将图像块嵌入到一个向量序列中。具体步骤如下：\n",
    "# 首先，输入图像的维度为 [B, C, H, W]，其中 B 是批次大小，C 是通道数，H 和 W 是图像的高度和宽度。\n",
    "# 然后，代码通过一个卷积层 self.proj 将图像块投影（Embedding）到一个新的向量空间。\n",
    "# 这个投影操作与图像块的大小和嵌入向量的维度有关。\n",
    "# 接下来，通过 flatten 方法将卷积输出展平为一个形状为 [B, C, H*W] 的张量，其中 H*W 表示图像中的总块数。\n",
    "# 最后，通过 transpose 方法将维度重新排列为 [B, H*W, C]，这样每个块就成为序列中的一个元素，\n",
    "# 其中 H*W 表示序列的长度，C 是块嵌入向量的维度。\n",
    "##########################################################################################\n",
    "##########################################################################################\n",
    "class PatchEmbed(nn.Layer):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        # 原始大小为int，转为tuple，即：img_size原始输入224，变换后为[224,224]\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        # 图像块的个数\n",
    "        num_patches = (img_size[1] // patch_size[1]) * (img_size[0] // patch_size[0])\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "\n",
    "        self.proj = nn.Conv2D(\n",
    "            in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        # in_chans：输入图像的通道数，默认为 3（RGB图像）。\n",
    "        # embed_dim：块嵌入向量的维度，默认为 768。\n",
    "        # kernel_size：卷积核大小，默认为 patch_size。\n",
    "        # stride：卷积步长，默认为 patch_size。\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape # 将x.shape的四个维度分别赋值给这四个变量，x是张量。\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
    "            \"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\" # 用于检查输入图像的大小是否与模型期望的大小相匹配。\n",
    "        # [B, C, H, W] -> [B, C, H*W] ->[B, H*W, C]\n",
    "        x = self.proj(x).flatten(2).transpose((0, 2, 1))\n",
    "        # self.proj在__init__中定义为一个2D卷积核。\n",
    "        # flatten(2)表示将第2维度的数据展平，即：[B, C, H*W]\n",
    "        # transpose((0, 2, 1))表示将第1维度和第2维度的数据交换，即：[B, H*W, C]，这样刚好是序列数据的表示方式。\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
